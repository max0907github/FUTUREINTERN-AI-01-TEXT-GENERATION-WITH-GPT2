# Text Generation with GPT-2

## Overview
This project utilizes the GPT-2 model for generating text based on prompts derived from a dataset containing various subjects and modal variants.

## Requirements
- Python 3.x
- Jupyter Notebook
- Libraries: `transformers`, `torch`, `pandas`

## Installation
1. Clone the repository:
    ```bash
    git clone <repository-url>
    cd <repository-directory>
    ```
   
2. Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```

## Usage
1. Open the Jupyter Notebook.
2. Run all cells in order to load the dataset and generate text.
3. The generated responses will be saved in `generated_responses.csv`.

## Dataset
The dataset used is `ManaGPT-1020_4080_prompts_and_generated_texts.csv`, which contains various prompts for text generation.

## License
This project is licensed under the MIT License.
